{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7214685,"sourceType":"datasetVersion","datasetId":4170975},{"sourceId":7243788,"sourceType":"datasetVersion","datasetId":4191015,"isSourceIdPinned":false}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install sacrebleu\nimport collections, json, pickle, time\nimport numpy\nimport tensorflow as tf\n\nfrom datasets import load_metric\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model, Sequential\nfrom keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM, Embedding\nfrom keras.optimizers import Adam\nfrom keras.losses import sparse_categorical_crossentropy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numpy.random.seed(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try: import wandb\nexcept:\n    ! pip install wandb\nimport wandb\nwandb.login(key = \"280aa3837eb27ece3c32ed8e27e3e233d0afdc9c\")\nwandb.init(\"Model Keras Project Deep learning\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"config = {\n    ### Mode\n    \"train_mode\": False,\n    \n    \"translate_mode\": False,\n    \"save_trans_pickle_file\": \"/kaggle/working/translated.pickle\",\n    \n    \"eval_mode\": False,\n    \n    ### Thông số dataset\n    \"train_file\": \"/kaggle/input/phomt-dl-2023-1/PhoMT_json/tokenization/train/train.json\",\n    \"dev_file\": \"/kaggle/input/phomt-dl-2023-1/PhoMT_json/tokenization/dev/dev.json\",\n    \"test_file\": \"/kaggle/input/phomt-dl-2023-1/PhoMT_json/tokenization/test/test.json\",\n    \"small_train_data\": 20000, # 20000\n    \n    ### Thông số train\n    \"epoch\" : 2, # 70\n    \"batch_size\" : 128,\n    \"learning_rate\": 0.003,\n    \n    ### Model ban đầu để load train tiếp hoặc infer\n    \"initial_model\": \"/kaggle/input/model-weight-and-translated-sentences-project-dl/save_model.keras\",\n    \n    ### File save model\n    \"save_model\": \"/kaggle/working/save_model.keras\"\n    \n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Các hàm phụ","metadata":{}},{"cell_type":"code","source":"def logits_to_text(logits, tokenizer):\n    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n    index_to_words[0] = '<PAD>'\n\n    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Dataset","metadata":{}},{"cell_type":"code","source":"def load_data(json_file, train):\n    en_sentences = list()\n    vi_sentences = list()\n    \n    with open(json_file, \"r\") as f:\n        data = json.load(f)[\"data\"]\n        \n    if train and config[\"small_train_data\"] != 0:\n        data = numpy.random.choice(a = data, \n                                   size = config[\"small_train_data\"])\n    \n    for sample in data:\n        en_sentences.append(sample[\"translation\"][\"en\"].strip().lower())\n        vi_sentences.append(sample[\"translation\"][\"vi\"].strip().lower())\n    return en_sentences, vi_sentences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm tokenize:\ndef tokenize(x):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(x)\n    return tokenizer.texts_to_sequences(x), tokenizer\n\n# Hàm padding:\ndef pad(x, length=None):\n    return pad_sequences(x, maxlen=length, padding='post')\n\n# Hàm preprocess: kết hợp của 2 hàm tokenize và padding, tokenize trước rồi padding\ndef preprocess(x, y, max_x_length = None, max_y_length = None):\n    ### Tokenize\n    preprocess_x, x_tk = tokenize(x)\n    preprocess_y, y_tk = tokenize(y)\n\n    ### Padding\n    preprocess_x = pad(preprocess_x, max_x_length)\n    preprocess_y = pad(preprocess_y, max_y_length)\n\n    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n\n    return preprocess_x, preprocess_y, x_tk, y_tk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model ","metadata":{}},{"cell_type":"code","source":"def model_final(input_shape, output_sequence_length, english_vocab_size, vi_vocab_size):\n    \n    # Build the layers    \n    model = Sequential()\n    # Embedding\n    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\n                         input_shape=input_shape[1:]))\n    # Encoder\n    model.add(Bidirectional(GRU(128)))\n    model.add(RepeatVector(output_sequence_length))\n    \n    # Decoder\n    model.add(Bidirectional(GRU(128, return_sequences=True)))\n    model.add(TimeDistributed(Dense(512, activation='relu')))\n    model.add(Dropout(0.5))\n    model.add(TimeDistributed(Dense(vi_vocab_size, activation='softmax')))\n    model.compile(loss=sparse_categorical_crossentropy,\n                  optimizer=Adam(config[\"learning_rate\"]),\n                  metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Hàm train và eval","metadata":{}},{"cell_type":"code","source":"def train(model, x, y):\n    model.summary()\n    model.fit(x, y, batch_size=config[\"batch_size\"], epochs=config[\"epoch\"], validation_split=0.2,\n             callbacks=[wandb.keras.WandbCallback()]\n             )\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def translate_the_set(en_sentences,\n                      model,\n                      en_tokenizer, vi_toknizer,\n                      max_en_length\n                      ):\n    y_id_to_word = {value: key for key, value in vi_tokenizer.word_index.items()}\n    y_id_to_word[0] = ''\n    translated_sentences = list()\n    for en_sen in en_sentences:\n        tokenized_en_sen = []\n        for word in en_sen.split():\n            try:\n                x = en_tokenizer.word_index[word]\n                tokenized_en_sen.append(x)\n            except KeyError:\n                continue\n        pad_en_sen = pad_sequences([tokenized_en_sen], maxlen = max_en_length, padding= \"post\")\n        translated_logits = model.predict(pad_en_sen, len(pad_en_sen))\n        translated_sen = ' '.join([y_id_to_word[numpy.argmax(x)] for x in translated_logits[0]])\n        translated_sentences.append(translated_sen)\n    \n    with open(config[\"save_trans_pickle_file\"], \"wb\") as f:\n        pickle.dump(translated_sentences, f)\n    return translated_sentences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_bleu(translated_sentences, # list[str]: list các câu dịch bởi model\n              vi_sentences          # list[str]: list các câu label\n              ):\n    t1 = time.time()\n    bleu_metric = load_metric(\"sacrebleu\")\n\n    for translated_sen, reference in zip(translated_sentences, vi_sentences):\n        bleu_metric.add(prediction = translated_sen, reference = [reference])\n    \n    result = bleu_metric.compute()\n    t2 = time.time()\n    print(f\"Đã tính bleu score xong!\\nTime = {t2 - t1} \")\n    print(f\"Bleu score = {result['score']}\")\n\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run","metadata":{}},{"cell_type":"code","source":"### Tạo và xử lý data\nen_sentences_train, vi_sentences_train = load_data(config[\"train_file\"], train = True)\nen_sentences_test, vi_sentences_test = load_data(config[\"test_file\"], train = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preproc_en_sentences, preproc_vi_sentences, en_tokenizer, vi_tokenizer = preprocess(en_sentences_train, vi_sentences_train)\nmax_en_length, max_vi_length = preproc_en_sentences.shape[1], preproc_vi_sentences.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Tạo model\nif config[\"initial_model\"] != None:\n    model = tf.keras.models.load_model(config[\"initial_model\"])\nelse:\n    model = model_final(preproc_en_sentences.shape, preproc_vi_sentences.shape[1],\n                       len(en_tokenizer.word_index)+1, len(vi_tokenizer.word_index)+1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Train\nif config[\"train_mode\"]:\n    train(model, preproc_en_sentences, preproc_vi_sentences)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Translate\nif config[\"translate_mode\"]:\n    translated_sentences = translate_the_set(en_sentences_test,\n                      model,\n                      en_tokenizer,\n                      vi_tokenizer,\n                      max_en_length\n                      )\n    result = eval_bleu(translated_sentences, vi_sentences_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SAVE","metadata":{}},{"cell_type":"code","source":"tf.keras.models.save_model(model, config[\"save_model\"])\nprint(\"Đã save model!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
