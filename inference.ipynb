{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7190659,"sourceType":"datasetVersion","datasetId":4152616},{"sourceId":7205338,"sourceType":"datasetVersion","datasetId":4164023,"isSourceIdPinned":true},{"sourceId":7214685,"sourceType":"datasetVersion","datasetId":4170975}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        print()\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-17T09:48:33.851681Z","iopub.execute_input":"2023-12-17T09:48:33.852417Z","iopub.status.idle":"2023-12-17T09:48:34.328110Z","shell.execute_reply.started":"2023-12-17T09:48:33.852375Z","shell.execute_reply":"2023-12-17T09:48:34.327177Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# from huggingface_hub import notebook_login\n\n# notebook_login()\n!huggingface-cli login --token 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\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:48:34.329798Z","iopub.execute_input":"2023-12-17T09:48:34.330283Z","iopub.status.idle":"2023-12-17T09:48:36.044279Z","shell.execute_reply.started":"2023-12-17T09:48:34.330253Z","shell.execute_reply":"2023-12-17T09:48:36.043286Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"18f117981791693b1b5befd22eb67d03d9bca621\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:48:36.045771Z","iopub.execute_input":"2023-12-17T09:48:36.046108Z","iopub.status.idle":"2023-12-17T09:48:39.895228Z","shell.execute_reply.started":"2023-12-17T09:48:36.046075Z","shell.execute_reply":"2023-12-17T09:48:39.894192Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"print(os.environ.get(\"HUGGINGFACE_HUB_TOKEN\"))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:48:39.896288Z","iopub.execute_input":"2023-12-17T09:48:39.896755Z","iopub.status.idle":"2023-12-17T09:48:39.902456Z","shell.execute_reply.started":"2023-12-17T09:48:39.896727Z","shell.execute_reply":"2023-12-17T09:48:39.901213Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers datasets evaluate sacrebleu huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:48:39.905480Z","iopub.execute_input":"2023-12-17T09:48:39.905830Z","iopub.status.idle":"2023-12-17T09:48:53.265641Z","shell.execute_reply.started":"2023-12-17T09:48:39.905739Z","shell.execute_reply":"2023-12-17T09:48:53.264516Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting sacrebleu\n  Obtaining dependency information for sacrebleu from https://files.pythonhosted.org/packages/de/ea/025db0a39337b63d4728a900d262c39c3029b0fe76a9876ce6297b1aa6a0/sacrebleu-2.4.0-py3-none-any.whl.metadata\n  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.12.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nCollecting portalocker (from sacrebleu)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.5.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu, evaluate\nSuccessfully installed evaluate-0.4.1 portalocker-2.8.2 sacrebleu-2.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"## VINAI DATASET\nfrom datasets import load_dataset\ndetoken_data_files = {\n    \"train\": \"/kaggle/input/phomt-dl-2023-1/PhoMT_json/detokenization/train/train.json\",\n    \"dev\": \"/kaggle/input/phomt-dl-2023-1/PhoMT_json/detokenization/dev/dev.json\",\n    \"test\": \"/kaggle/input/phomt-dl-2023-1/PhoMT_json/detokenization/test/test.json\"\n}\n\ndetoken_data = load_dataset(\"json\", data_files = detoken_data_files, field = \"data\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:48:53.268960Z","iopub.execute_input":"2023-12-17T09:48:53.269397Z","iopub.status.idle":"2023-12-17T09:49:23.678307Z","shell.execute_reply.started":"2023-12-17T09:48:53.269349Z","shell.execute_reply":"2023-12-17T09:49:23.677591Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-20e1a35b2923cfa1/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f85d06ac341e4c3c81def71f5e39d786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a2e656aeed4cafb355b11e48c01c20"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-20e1a35b2923cfa1/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd0fe589516c4b069e96674c39b4ed5d"}},"metadata":{}}]},{"cell_type":"code","source":"detoken_data","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.679658Z","iopub.execute_input":"2023-12-17T09:49:23.680179Z","iopub.status.idle":"2023-12-17T09:49:23.687043Z","shell.execute_reply.started":"2023-12-17T09:49:23.680148Z","shell.execute_reply":"2023-12-17T09:49:23.685997Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 2978000\n    })\n    dev: Dataset({\n        features: ['translation'],\n        num_rows: 18720\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 19152\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset = detoken_data\ndataset[\"train\"] = dataset[\"train\"].select(range(10))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.688780Z","iopub.execute_input":"2023-12-17T09:49:23.689410Z","iopub.status.idle":"2023-12-17T09:49:23.710593Z","shell.execute_reply.started":"2023-12-17T09:49:23.689377Z","shell.execute_reply":"2023-12-17T09:49:23.709423Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# ## MTET DATASET\n# from datasets import load_dataset\n\n# dataset = load_dataset(\"phongmt184172/mtet\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.712265Z","iopub.execute_input":"2023-12-17T09:49:23.712874Z","iopub.status.idle":"2023-12-17T09:49:23.723652Z","shell.execute_reply.started":"2023-12-17T09:49:23.712841Z","shell.execute_reply":"2023-12-17T09:49:23.722520Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.725214Z","iopub.execute_input":"2023-12-17T09:49:23.725581Z","iopub.status.idle":"2023-12-17T09:49:23.741031Z","shell.execute_reply.started":"2023-12-17T09:49:23.725552Z","shell.execute_reply":"2023-12-17T09:49:23.739899Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 10\n    })\n    dev: Dataset({\n        features: ['translation'],\n        num_rows: 18720\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 19152\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.742282Z","iopub.execute_input":"2023-12-17T09:49:23.742648Z","iopub.status.idle":"2023-12-17T09:49:23.767786Z","shell.execute_reply.started":"2023-12-17T09:49:23.742619Z","shell.execute_reply":"2023-12-17T09:49:23.765989Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'translation': {'en': 'It begins with a countdown.',\n  'vi': 'Câu chuyện bắt đầu với buổi lễ đếm ngược.'}}"},"metadata":{}}]},{"cell_type":"code","source":"# REMOVE ALL TRAINING DATA EXCEPT 10 samples(ONLY INFERENCE IN THIS NOTEBOOK)\ndataset[\"train\"] = dataset[\"train\"].select(range(10))","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.768811Z","iopub.execute_input":"2023-12-17T09:49:23.769175Z","iopub.status.idle":"2023-12-17T09:49:23.783082Z","shell.execute_reply.started":"2023-12-17T09:49:23.769143Z","shell.execute_reply":"2023-12-17T09:49:23.781973Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# books = load_dataset(\"opus_books\", \"en-fr\")\n# books = books[\"train\"].train_test_split(test_size=0.2)\n# books[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.784323Z","iopub.execute_input":"2023-12-17T09:49:23.784993Z","iopub.status.idle":"2023-12-17T09:49:23.795020Z","shell.execute_reply.started":"2023-12-17T09:49:23.784961Z","shell.execute_reply":"2023-12-17T09:49:23.794019Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ncheckpoint = \"ngocquanofficial/machine_translation_with_V100_second\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:23.801317Z","iopub.execute_input":"2023-12-17T09:49:23.802160Z","iopub.status.idle":"2023-12-17T09:49:36.626558Z","shell.execute_reply.started":"2023-12-17T09:49:23.802116Z","shell.execute_reply":"2023-12-17T09:49:36.625708Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"916ffed715ba4be1a6c2413e33082bc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d281435d0d4121a690c154e34a24c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7a254aa1897402db289bb506f48043c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/770 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f598ac2a4ae4b6490f6de5bf131c02d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"439c8d142b66442f918daf4679781de3"}},"metadata":{}}]},{"cell_type":"code","source":"model_name = model.config._name_or_path\nprint(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:36.627924Z","iopub.execute_input":"2023-12-17T09:49:36.628734Z","iopub.status.idle":"2023-12-17T09:49:36.633035Z","shell.execute_reply.started":"2023-12-17T09:49:36.628702Z","shell.execute_reply":"2023-12-17T09:49:36.631888Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"ngocquanofficial/machine_translation_with_V100\n","output_type":"stream"}]},{"cell_type":"code","source":"# PREPROCESS FOR VINAI DATASET\nsource_lang = \"en\"\ntarget_lang = \"vi\"\nprefix = \"translate to Vietnamese: \"\nmax_length = 128\n\ndef preprocess_function(examples):\n    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n    targets = [example[target_lang] for example in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n    return model_inputs\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:36.634414Z","iopub.execute_input":"2023-12-17T09:49:36.634819Z","iopub.status.idle":"2023-12-17T09:49:36.653230Z","shell.execute_reply.started":"2023-12-17T09:49:36.634783Z","shell.execute_reply":"2023-12-17T09:49:36.652275Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# # PROCESS FOR MTET DATASET\n# def preprocess_function(examples):\n#     vi_sentences= []\n#     en_sentences = []\n#     inputs = []\n#     targets = []\n#     for prompt in examples[\"prompt\"] :\n#         prompt = prompt.split(\":\")[0]\n#         prompt = prompt.lower().split(\" \")\n#         english = \"english\"\n#         vietnamese = \"vietnamese\"\n#         if english in prompt or \"anh\" in prompt :\n#             en_sentence = \"target\"\n#             vi_sentence = \"source\"\n#         elif vietnamese in prompt or \"việt\" in prompt :\n#             en_sentence = \"source\"\n#             vi_sentence = \"target\"\n#         else :\n#             print(prompt)\n#         en_sentences.append(en_sentence)\n#         vi_sentences.append(vi_sentence)\n#     for i, example in enumerate(examples[\"translation\"]) :\n        \n#         # JUST FOR CHECKING \n#         a = random.randint(1, 700)\n#         if a == 1 :\n#             print(example[en_sentences[i]])\n#             print(example[vi_sentences[i]])\n#             print()\n            \n            \n#         input_value = example[en_sentences[i]]\n#         target_value = example[vi_sentences[i]]\n#         inputs.append(input_value)\n#         targets.append(target_value)\n\n#     model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n#     return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:36.654682Z","iopub.execute_input":"2023-12-17T09:49:36.655100Z","iopub.status.idle":"2023-12-17T09:49:36.667450Z","shell.execute_reply.started":"2023-12-17T09:49:36.655062Z","shell.execute_reply":"2023-12-17T09:49:36.666558Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenizer_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:36.668809Z","iopub.execute_input":"2023-12-17T09:49:36.669222Z","iopub.status.idle":"2023-12-17T09:49:41.153529Z","shell.execute_reply.started":"2023-12-17T09:49:36.669184Z","shell.execute_reply":"2023-12-17T09:49:41.152652Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f603fe59bb2452ab9339a8d6f9f9396"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2d1cce11dd94121af207fc52437edcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0063092dd41409eb3e80ee01a903bbc"}},"metadata":{}}]},{"cell_type":"code","source":"# tokenized_books[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:41.154619Z","iopub.execute_input":"2023-12-17T09:49:41.155326Z","iopub.status.idle":"2023-12-17T09:49:41.160695Z","shell.execute_reply.started":"2023-12-17T09:49:41.155284Z","shell.execute_reply":"2023-12-17T09:49:41.159422Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model= model)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:41.162317Z","iopub.execute_input":"2023-12-17T09:49:41.163199Z","iopub.status.idle":"2023-12-17T09:49:56.716250Z","shell.execute_reply.started":"2023-12-17T09:49:41.163144Z","shell.execute_reply":"2023-12-17T09:49:56.715358Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:56.717324Z","iopub.execute_input":"2023-12-17T09:49:56.717939Z","iopub.status.idle":"2023-12-17T09:49:59.861807Z","shell.execute_reply.started":"2023-12-17T09:49:56.717909Z","shell.execute_reply":"2023-12-17T09:49:59.860870Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc8384aceacf458986685a871045bc78"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:59.862871Z","iopub.execute_input":"2023-12-17T09:49:59.863561Z","iopub.status.idle":"2023-12-17T09:49:59.868699Z","shell.execute_reply.started":"2023-12-17T09:49:59.863530Z","shell.execute_reply":"2023-12-17T09:49:59.867671Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:59.870004Z","iopub.execute_input":"2023-12-17T09:49:59.870347Z","iopub.status.idle":"2023-12-17T09:49:59.886845Z","shell.execute_reply.started":"2023-12-17T09:49:59.870303Z","shell.execute_reply":"2023-12-17T09:49:59.885950Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Calculate Sacrebleu\n\ndef compute_metrics(prediction, label):\n\n    bleu_metric = load_metric('sacrebleu')\n\n    bleu_metric.add(prediction= prediction, reference= label)\n\n    bleu_score = bleu_metric.compute()\n    print(f\"BLEU score: {bleu_score['score']}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:59.887975Z","iopub.execute_input":"2023-12-17T09:49:59.888280Z","iopub.status.idle":"2023-12-17T09:49:59.896676Z","shell.execute_reply.started":"2023-12-17T09:49:59.888254Z","shell.execute_reply":"2023-12-17T09:49:59.895789Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## INFERENCE","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:59.897856Z","iopub.execute_input":"2023-12-17T09:49:59.898668Z","iopub.status.idle":"2023-12-17T09:49:59.938079Z","shell.execute_reply.started":"2023-12-17T09:49:59.898638Z","shell.execute_reply":"2023-12-17T09:49:59.937247Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"text = \"I am a junior student at university, from a developing country.\"","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:59.939278Z","iopub.execute_input":"2023-12-17T09:49:59.939717Z","iopub.status.idle":"2023-12-17T09:49:59.944292Z","shell.execute_reply.started":"2023-12-17T09:49:59.939681Z","shell.execute_reply":"2023-12-17T09:49:59.943334Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\n\n# Assuming 'text' is your input text\n\ntext = \"I am a third year student at Hanoi University of Science and Technology.\"\n\n# Tokenize the input text\ninputs = tokenizer(text, return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"]\nprint(input_ids)\n\n# Generate outputs on the same device as the input\noutputs = model.generate(input_ids, max_length=40, do_sample=True, top_k=30, top_p=0.95)\n\n# Decode the generated output\ndecoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(decoded_output)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:49:59.945723Z","iopub.execute_input":"2023-12-17T09:49:59.946092Z","iopub.status.idle":"2023-12-17T09:50:00.844083Z","shell.execute_reply.started":"2023-12-17T09:49:59.946056Z","shell.execute_reply":"2023-12-17T09:50:00.842983Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"tensor([[  288,  3859,  2071,   868, 11339, 22444, 30986,  5743, 23325,  9966,\n          2174, 12713,  2970, 17301, 35792,     1]])\nTôi là sinh viên năm ba trường Đại học Khoa học và Công nghệ Hà Nội.\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Load the model and tokenizer\n# model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/checkpoint-14-12-10-epochs-full-dataset/machine_translation_from_huster\")\n# tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/checkpoint-14-12-10-epochs-full-dataset/machine_translation_from_huster\")\n\n\n# prev_model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/checkpoint-11-12-2023/machine_translation_from_huster\")\n# prev_tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/checkpoint-11-12-2023/machine_translation_from_huster\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:50:00.845422Z","iopub.execute_input":"2023-12-17T09:50:00.846489Z","iopub.status.idle":"2023-12-17T09:50:00.851476Z","shell.execute_reply.started":"2023-12-17T09:50:00.846430Z","shell.execute_reply":"2023-12-17T09:50:00.850393Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def infer(text, model, tokenizer) :\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"]\n    outputs = model.generate(input_ids, max_length= 128, do_sample=True, top_k=30, top_p=0.95)\n    # Decode the generated output\n    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return decoded_output\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:50:00.853013Z","iopub.execute_input":"2023-12-17T09:50:00.853657Z","iopub.status.idle":"2023-12-17T09:50:00.863239Z","shell.execute_reply.started":"2023-12-17T09:50:00.853620Z","shell.execute_reply":"2023-12-17T09:50:00.862430Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Calculate Sacrebleu\n\ndef compute_metrics(prediction, label):\n\n    bleu_metric = load_metric('sacrebleu')\n\n    bleu_metric.add(prediction= prediction, reference= label)\n\n    bleu_score = bleu_metric.compute()\n    return bleu_score[\"score\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:50:00.864647Z","iopub.execute_input":"2023-12-17T09:50:00.865266Z","iopub.status.idle":"2023-12-17T09:50:00.886925Z","shell.execute_reply.started":"2023-12-17T09:50:00.865227Z","shell.execute_reply":"2023-12-17T09:50:00.886103Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"tokenizer_dataset[\"test\"] = tokenizer_dataset[\"test\"].shuffle(seed= 236)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:50:00.888228Z","iopub.execute_input":"2023-12-17T09:50:00.888790Z","iopub.status.idle":"2023-12-17T09:50:00.912584Z","shell.execute_reply.started":"2023-12-17T09:50:00.888760Z","shell.execute_reply":"2023-12-17T09:50:00.911621Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\n# def infer_mtet_test_set(model, tokenizer_dataset, times, skip_small_text= 0) :\n#     count = 0\n#     import random\n#     import numpy as np\n#     bleu = np.array([])\n#     for text_dict in tokenizer_dataset[\"test\"] :\n#         if count == 20 :\n#             break\n\n#         # SPECIAL ONLY FOR MTET DATASET\n#         prompt = text_dict[\"prompt\"]\n#         prompt = prompt.split(\":\")[0]\n#         prompt = prompt.lower().split(\" \")\n#         english = \"english\"\n#         vietnamese = \"vietnamese\"\n#         if english in prompt or \"anh\" in prompt :\n#             en_sentence = \"target\"\n#             vi_sentence = \"source\"\n#         elif vietnamese in prompt or \"việt\" in prompt :\n#             en_sentence = \"source\"\n#             vi_sentence = \"target\"\n#         text = text_dict[\"translation\"][en_sentence]\n#         label = text_dict[\"translation\"][vi_sentence]\n#         #########################3\n\n#         if skip_small_text > 0 :\n#             if len(text) < skip_small_text :\n#                 continue\n#         count += 1\n\n#         output_list = []\n#         bleu_score_list = []\n#         # Infer times times with same input\n#         for i in range(times) :\n#             output = infer(text, model, tokenizer)\n#             score = compute_metrics([output], [label])\n#             output_list.append(output)\n#             bleu_score_list.append(score)\n#         # Got largest blue score\n#         max_index = bleu_score_list.index(max(bleu_score_list))\n#         bleu_score = bleu_score_list[max_index]\n#         bleu = np.append(bleu, bleu_score)\n\n#         print(\"Bleu Score: \", bleu_score_list[max_index])\n#         print(\"Prediction: \" + output_list[max_index])\n#         print(\"Label: \" + label)\n#         print(len(text))\n\n#         print()\n#     print(bleu)\n#     print(bleu.mean())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:50:00.913905Z","iopub.execute_input":"2023-12-17T09:50:00.914599Z","iopub.status.idle":"2023-12-17T09:50:00.919984Z","shell.execute_reply.started":"2023-12-17T09:50:00.914568Z","shell.execute_reply":"2023-12-17T09:50:00.918917Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\ndef infer_test_set(model, tokenizer_dataset, times, skip_small_text= 0, sample= 500) :\n    count = 0\n    import random\n    import numpy as np\n    bleu = np.array([])\n    for text_dict in tokenizer_dataset[\"test\"] :\n        if count == sample :\n            break\n\n        text = text_dict[\"translation\"][\"en\"]\n        label = text_dict[\"translation\"][\"vi\"]\n\n        if skip_small_text > 0 :\n            if len(text) < skip_small_text :\n                continue\n        count += 1\n\n        output_list = []\n        bleu_score_list = []\n        # Infer times times with same input\n        for i in range(times) :\n            output = infer(text, model, tokenizer)\n            score = compute_metrics([output], [label])\n            output_list.append(output)\n            bleu_score_list.append(score)\n        # Got largest blue score\n        max_index = bleu_score_list.index(max(bleu_score_list))\n        bleu_score = bleu_score_list[max_index]\n        bleu = np.append(bleu, bleu_score)\n        \n        if count % 100 != 0 :\n            continue\n        print(\"Bleu Score: \", bleu_score_list[max_index])\n        print(\"Input: \" + text)\n        print(\"Prediction: \" + output_list[max_index])\n        print(\"Label: \" + label)\n        print()\n\n    print(f\"Length: {len(bleu)}\")\n    if skip_small_text > 0 :\n        print(f\"MEAN BLEU SCORE with loop= {times}, skip all text with length shorter than {skip_small_text}: {bleu.mean()}\")\n    else :\n        print(f\"MEAN BLEU SCORE with loop= {times}, do not skip small text: {bleu.mean()}\")\n    print(\"BLEU SCORE: \", bleu.mean())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:10:54.648779Z","iopub.execute_input":"2023-12-17T10:10:54.649269Z","iopub.status.idle":"2023-12-17T10:10:54.661505Z","shell.execute_reply.started":"2023-12-17T10:10:54.649233Z","shell.execute_reply":"2023-12-17T10:10:54.660509Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"infer_test_set(model= model, tokenizer_dataset= tokenizer_dataset, times= 5, skip_small_text= 40, sample= 1000)\nprint(model.config._name_or_path)\nprint()\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:10:57.543315Z","iopub.execute_input":"2023-12-17T10:10:57.544010Z","iopub.status.idle":"2023-12-17T10:12:17.314889Z","shell.execute_reply.started":"2023-12-17T10:10:57.543978Z","shell.execute_reply":"2023-12-17T10:12:17.313124Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Length: 10\nMEAN BLEU SCORE with loop= 5, skip all text with length shorter than 40: 24.598150443953383\nBLEU SCORE:  24.598150443953383\nngocquanofficial/machine_translation_with_V100\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"infer_test_set(model= model, tokenizer_dataset= tokenizer_dataset, times= 10, skip_small_text= 40, sample= 1000)\nprint(model.config._name_or_path)\nprint()\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:12:17.316991Z","iopub.execute_input":"2023-12-17T10:12:17.317411Z","iopub.status.idle":"2023-12-17T10:14:45.021366Z","shell.execute_reply.started":"2023-12-17T10:12:17.317370Z","shell.execute_reply":"2023-12-17T10:14:45.020354Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Length: 10\nMEAN BLEU SCORE with loop= 10, skip all text with length shorter than 40: 32.426572363489704\nBLEU SCORE:  32.426572363489704\nngocquanofficial/machine_translation_with_V100\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"infer_test_set(model= model, tokenizer_dataset= tokenizer_dataset, times= 1, skip_small_text= 40, sample= 1000)\nprint(model.config._name_or_path)\nprint()\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:14:45.022838Z","iopub.execute_input":"2023-12-17T10:14:45.023139Z","iopub.status.idle":"2023-12-17T10:14:59.958269Z","shell.execute_reply.started":"2023-12-17T10:14:45.023111Z","shell.execute_reply":"2023-12-17T10:14:59.957297Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Length: 10\nMEAN BLEU SCORE with loop= 1, skip all text with length shorter than 40: 16.84404085122897\nBLEU SCORE:  16.84404085122897\nngocquanofficial/machine_translation_with_V100\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"infer_test_set(model= model, tokenizer_dataset= tokenizer_dataset, times= 5, skip_small_text= -1, sample= 1000)\nprint(model.config._name_or_path)\nprint()\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:14:59.962668Z","iopub.execute_input":"2023-12-17T10:14:59.962972Z","iopub.status.idle":"2023-12-17T10:15:13.365413Z","shell.execute_reply.started":"2023-12-17T10:14:59.962944Z","shell.execute_reply":"2023-12-17T10:15:13.364461Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Length: 10\nMEAN BLEU SCORE with loop= 1, do not skip small text: 16.706328478514756\nBLEU SCORE:  16.706328478514756\nngocquanofficial/machine_translation_with_V100\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"infer_test_set(model= model, tokenizer_dataset= tokenizer_dataset, times= 10, skip_small_text= -1, sample= 1000)\nprint(model.config._name_or_path)\nprint()\nprint()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer_test_set(model= model, tokenizer_dataset= tokenizer_dataset, times= 1, skip_small_text= -1, sample= 1000)\nprint(model.config._name_or_path)\nprint()\nprint()","metadata":{},"execution_count":null,"outputs":[]}]}